{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Entry Point [tensor2tensor.envs.tic_tac_toe_env:TicTacToeEnv] registered with id [T2TEnv-TicTacToeEnv-v0]\n"
     ]
    }
   ],
   "source": [
    "# Imports we need.\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "# Enable TF Eager execution\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "# Other setup\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping generator because outputs files exists at ['data/sentiment_imdb/sentiment_imdb-unshuffled-train-00000-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00001-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00002-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00003-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00004-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00005-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00006-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00007-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00008-of-00010', 'data/sentiment_imdb/sentiment_imdb-unshuffled-train-00009-of-00010']\n",
      "INFO:tensorflow:Skipping generator because outputs files exists at ['data/sentiment_imdb/sentiment_imdb-unshuffled-dev-00000-of-00001']\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "data_dir='data/sentiment_imdb'\n",
    "tmp_dir='tmp'\n",
    "\n",
    "# Fetch the MNIST problem\n",
    "imdb_problem = problems.problem(\"sentiment_imdb\")\n",
    "# The generate_data method of a problem will download data and process it into\n",
    "# a standard format ready for training and evaluation.\n",
    "imdb_problem.generate_data(data_dir, tmp_dir)\n",
    "\n",
    "\n",
    "# Get the encoders from the problem\n",
    "imdb_encoders = imdb_problem.feature_encoders(data_dir)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  inputs = imdb_encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
    "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
    "  return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "  \"\"\"List of ints to str\"\"\"\n",
    "  integers = list(np.squeeze(integers))\n",
    "  if 1 in integers:\n",
    "    integers = integers[:integers.index(1)]\n",
    "  return imdb_encoders[\"inputs\"].decode(np.squeeze(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from data/sentiment_imdb/sentiment_imdb-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "WARNING:tensorflow:From /home/samira/anaconda3/envs/myt2t/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "input: As far as the Muppet line goes, however, this is not the best, nor the second best. This was marketed towards the kiddies, but has some dark, and emotionally upsetting adult moments, to which parents may not wish to expose their children. One of which showcases Miss Piggy going \"postal\" in a jealous rage, which lasts basically throughout the duration of this work.<br /><br />Beyond that, however, the story is progressive, and highly entertaining. One scene in which Joan Rivers and Miss PIggy go berserk in a department store is simply hilarious! And there are other parts of this work which contain the same level of levity and fun.<br /><br />I like this very much, and enjoy it still today.<br /><br />It rates a 7.6/10 from...<br /><br />the Fiend :.\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Now let's see the training MNIST data as Tensors.\n",
    "imdb_example = tfe.Iterator(imdb_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
    "inputs = imdb_example[\"inputs\"]\n",
    "label = imdb_example[\"targets\"]\n",
    "\n",
    "print(\"input:\", decode(inputs))\n",
    "print(\"Label: %d\" % label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    }
   ],
   "source": [
    "#@title Create the model\n",
    "# Create hparams and the model\n",
    "model_name = \"bottomup_transformer_encoder\"\n",
    "hparams_set = \"transformer_tiny\"\n",
    "\n",
    "hparams = trainer_lib.create_hparams(hparams_set, data_dir=data_dir, problem_name=\"sentiment_imdb\")\n",
    "\n",
    "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
    "# Layer and so subsequent instantiations will have different variable scopes\n",
    "# that will not match the checkpoint.\n",
    "imdb_model = registry.model(model_name)(hparams, Modes.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Utility functions\n",
    "from tensor2tensor.visualization import attention\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "\n",
    "SIZE = 35\n",
    "\n",
    "def encode_eval(input_str, output_str):\n",
    "  inputs = tf.reshape(encoders[\"inputs\"].encode(input_str) + [1], [1, -1, 1, 1])  # Make it 3D.\n",
    "  outputs = tf.reshape(encoders[\"inputs\"].encode(output_str) + [1], [1, -1, 1, 1])  # Make it 3D.\n",
    "  return {\"inputs\": inputs, \"targets\": outputs}\n",
    "\n",
    "def get_att_mats():\n",
    "  assignment_weights = []\n",
    "  assignment_logits = []\n",
    "  weights = []\n",
    "  logits = []\n",
    "  presence_qz = []\n",
    "  presence_qz_logits = []\n",
    "\n",
    "  for i in range(hparams.num_hidden_layers):\n",
    "    assignment_weight = imdb_model.attention_weights[\n",
    "      \"bottomup_transformer_encoder/body/encoder/layer_%i/self_attention/multihead_attention/bottom_up_dot_product_attention/assignment_weights\" % i][0]\n",
    "    assignment_logit = imdb_model.attention_weights[\n",
    "      \"bottomup_transformer_encoder/body/encoder/layer_%i/self_attention/multihead_attention/bottom_up_dot_product_attention/assignment_logits\" % i][0]\n",
    "    weight = imdb_model.attention_weights[\n",
    "      \"bottomup_transformer_encoder/body/encoder/layer_%i/self_attention/multihead_attention/bottom_up_dot_product_attention/weights\" % i][0]\n",
    "    logit = imdb_model.attention_weights[\n",
    "      \"bottomup_transformer_encoder/body/encoder/layer_%i/self_attention/multihead_attention/bottom_up_dot_product_attention/logits\" % i][0]\n",
    "    presence_q = imdb_model.attention_weights[\n",
    "      \"bottomup_transformer_encoder/body/encoder/layer_%i/self_attention/multihead_attention/bottom_up_dot_product_attention/q_presence_probs\" % i][0]\n",
    "    presence_q_logit = imdb_model.attention_weights[\n",
    "      \"bottomup_transformer_encoder/body/encoder/layer_%i/self_attention/multihead_attention/bottom_up_dot_product_attention/q_presence_logits\" % i][0]\n",
    "\n",
    "    assignment_weights.append(resize(assignment_weight))\n",
    "    assignment_logits.append(resize(assignment_logit))\n",
    "    weights.append(resize(weight))\n",
    "    logits.append(resize(logit))\n",
    "    presence_qz.append(presence_q)\n",
    "    presence_qz_logits.append(presence_q_logit)\n",
    "\n",
    "  return assignment_weights, assignment_logits, weights, logits, presence_qz, presence_qz_logits\n",
    "\n",
    "def resize(np_mat):\n",
    "  # Sum across heads\n",
    "  np_mat = np_mat[:, :SIZE, :SIZE]\n",
    "  row_sums = np.sum(np_mat, axis=0)\n",
    "  # Normalize\n",
    "  layer_mat = np_mat / row_sums[np.newaxis, :]\n",
    "  lsh = layer_mat.shape\n",
    "  # Add extra dim for viz code to work.\n",
    "  layer_mat = np.reshape(layer_mat, (1, lsh[0], lsh[1], lsh[2]))\n",
    "  return layer_mat\n",
    "\n",
    "def to_tokens(ids):\n",
    "  ids = np.squeeze(ids)\n",
    "  subtokenizer = hparams.problem_hparams.vocabulary['targets']\n",
    "  tokens = []\n",
    "  for _id in ids:\n",
    "    if _id == 0:\n",
    "      tokens.append('<PAD>')\n",
    "    elif _id == 1:\n",
    "      tokens.append('<EOS>')\n",
    "    elif _id == -1:\n",
    "      tokens.append('<NULL>')\n",
    "    else:\n",
    "        tokens.append(subtokenizer._subtoken_id_to_subtoken_string(_id))\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: The animal didn't cross the street because it was too tired\n",
      "Outputs: [[[[1]]]]\n"
     ]
    }
   ],
   "source": [
    "#@title Classify an example and get the attention mats\n",
    "# Restore and translate!\n",
    "def classify(inputs):\n",
    "  encoded_inputs = encode(inputs)\n",
    "  model_output = imdb_model.infer(encoded_inputs)[\"outputs\"]\n",
    "  return model_output.numpy()\n",
    "\n",
    "inputs = \"The animal didn't cross the street because it was too tired\"\n",
    "outputs = classify(inputs)\n",
    "\n",
    "print(\"Inputs: %s\" % inputs)\n",
    "print(\"Outputs: %s\" % outputs)\n",
    "\n",
    "assignment_weights, assignment_logits, weights, logits, presence_qz, presence_qz_logits = get_att_mats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer number: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer number: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Encoder attention at different layers\n",
    "\n",
    "attention_mat = assignment_weights\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "for layer in np.arange(len(attention_mat)):\n",
    "  print(\"Layer number: %d\" %layer)\n",
    "  axes = {}\n",
    "  for head in np.arange(1,5):\n",
    "    axes[head] = plt.subplot(1,4,head)\n",
    "    axes[head].imshow(attention_mat[layer][0][1])\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(14)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presence_qz[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Encoder presence prob at different layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "plt.imshow(presence_qz_logits, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(presence_qz, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
